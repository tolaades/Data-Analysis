{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Import necessary libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import neighbors\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Ingest + prep data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for calculating mean squared prediction error \n",
    "def mean_sq_prediction_error(y_actual, y_predicted):\n",
    "    mpe = ((y_actual - y_predicted)**2).mean()\n",
    "    print(\"Mean prediction error is % s\" % round(mpe, 5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and create data frame; call it \"reviews\"\n",
    "reviews = pd.read_csv(\"company_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert status into binary numerical format and clean up space around name\n",
    "status_dict = {'Former Employee': 0,'Former Employee ': 0,'Current Employee': 1, 'Current Employee ':1} \n",
    "reviews['status_num'] = [status_dict[item] for item in reviews.status]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> K-nearest neighbor </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> -- Continuous dependent variable </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution -- limits to KNN: can't handle lots of independent variables, especially lots of dummies \n",
    "# Start with a few independent variables and add one by one, testing predictive performance each time\n",
    "\n",
    "# Dependent variable can be either continuous or binary\n",
    "# When continuous, predicted value is the mean (average) of the neighbors' values\n",
    "\n",
    "# Isolate your X's and y -- continuous DV example\n",
    "independent = ['month', 'likes']\n",
    "dependent = 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data frame into training and test sets: 80% training; 20% test\n",
    "X = pd.get_dummies(reviews[independent], drop_first=True)\n",
    "y = reviews[dependent]\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize independent variables by setting them on a common scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "\n",
    "train_X = scaler.transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 1.42828568570857\n",
      "RMSE value for k=  2 is: 1.1565033506220377\n",
      "RMSE value for k=  3 is: 1.1306340404097752\n",
      "RMSE value for k=  4 is: 1.1021286222578561\n",
      "RMSE value for k=  5 is: 1.085172797300043\n",
      "RMSE value for k=  6 is: 1.0939860856316024\n",
      "RMSE value for k=  7 is: 1.0850561915290424\n",
      "RMSE value for k=  8 is: 1.066206769346359\n",
      "RMSE value for k=  9 is: 1.0644363256475347\n",
      "RMSE value for k=  10 is: 1.0672862783714592\n",
      "RMSE value for k=  11 is: 1.061945042234895\n",
      "RMSE value for k=  12 is: 1.065363787633126\n",
      "RMSE value for k=  13 is: 1.0514149384429845\n",
      "RMSE value for k=  14 is: 1.0437862788513592\n",
      "RMSE value for k=  15 is: 1.044775361288519\n",
      "RMSE value for k=  16 is: 1.0459930986866022\n",
      "RMSE value for k=  17 is: 1.0483798672336098\n",
      "RMSE value for k=  18 is: 1.046702641514335\n",
      "RMSE value for k=  19 is: 1.0456412630388727\n",
      "RMSE value for k=  20 is: 1.0455082496087729\n"
     ]
    }
   ],
   "source": [
    "# Select optimal k\n",
    "# k is called a \"hyperparameter\"\n",
    "rmse_val = [] # Set up object to store RMSE (root mean squared error) values for different k's\n",
    "\n",
    "for K in range(20):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(train_X, train_y)  # Fit the model\n",
    "    pred = model.predict(test_X) # make prediction on test set\n",
    "    error = sqrt(mean_squared_error(test_y, pred)) # Calculate RMSE\n",
    "    rmse_val.append(error) # Store RMSE values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the RMSE values against the k values\n",
    "curve = pd.DataFrame(rmse_val)  \n",
    "curve.plot()\n",
    "\n",
    "# Look for the \"elbow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative method: gridsearch\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "model.fit(train_X, train_y)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with k neighbors\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors = 9) # Set up the model\n",
    "model.fit(train_X, train_y)  # Fit the model to our training data\n",
    "predicted_y = model.predict(test_X) # Generate predicted values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prediction error is 1.13302\n"
     ]
    }
   ],
   "source": [
    "# Compute mean squared prediction error for comparison with other algorithms\n",
    "# Note that you can also follow the steps in previous weeks to eyeball and plot the actual vs. predicted values of y]\n",
    "mean_sq_prediction_error(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How did this model do compared to other predictive models used for continuous dependent variables? \n",
    "# Use mean squared prediction error as the common measurement of predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> -- Binary dependent variable </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate your X's and y -- categorical\n",
    "independent = ['month', 'score']\n",
    "dependent = 'status_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data frame into training and test sets: 80% training; 20% test\n",
    "X = pd.get_dummies(reviews[independent], drop_first=True)\n",
    "y = reviews[dependent]\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue as above with KNeighborsClassifier instead of KNeighborsRegressor\n",
    "# Rule of thumb: use an odd number for k if you have a binary dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-4075a66679b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute F1 score for comparison with other algorithms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \"\"\"\n\u001b[1;32m-> 1044\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \"\"\"\n\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1169\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1434\u001b[0m                                     pos_label)\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                          str(average_options))\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Compute F1 score for comparison with other algorithms\n",
    "metrics.f1_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> -- Just for fun: KNN visualization tutorials </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works for a continuous y and a single continuous x.\n",
    "# 2D tutorial here: https://towardsdatascience.com/knn-visualization-in-just-13-lines-of-code-32820d72c6b6\n",
    "\n",
    "# This one works with a continuous y and two continuous x's.\n",
    "# 3D tutorial here: https://www.kaggle.com/skalskip/iris-data-visualization-and-knn-classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Targeted predictions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "month_Aug\n",
      "month_Dec\n",
      "month_Feb\n",
      "month_Jan\n",
      "month_Jul\n",
      "month_Jun\n",
      "month_Mar\n",
      "month_May\n",
      "month_Nov\n",
      "month_Oct\n",
      "month_Sep\n"
     ]
    }
   ],
   "source": [
    "# Recall the distinction between interpretation/explanation and prediction\n",
    "# How to open the black box?\n",
    "# -- regression table\n",
    "# -- variable importance (trees/forests)\n",
    "# -- play with different sets of inputs to produce targeted predictions\n",
    "\n",
    "# Choose your best-performing model -- regression, decision tree, random forest, KNN\n",
    "# Using KNN here as an example\n",
    "\n",
    "# Define your new input \n",
    "# Follow the same order as the independent variables you identified above: ['month', 'likes'] \n",
    "# Note that you'll need to use the dummy formatting if necessary\n",
    "\n",
    "# View the columns names if you need a refresher \n",
    "for col in X.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up new inputs\n",
    "new_input = [[5, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.11111111])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run new inputs through predictive model created above to produce targeted prediction of the value of y\n",
    "new_output = model.predict(new_input)\n",
    "new_output\n",
    "\n",
    "# Remember that for binary dependent variables, output is probability that y = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify the workflow above for trees or forests\n",
    "# Example code below uses tree_cont model from week 8\n",
    "# new_input here would need to contain values for whichever x's you identified in your \"independent\" object\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_cont = DecisionTreeRegressor()\n",
    "tree_cont = tree_cont.fit(train_X, train_y)\n",
    "\n",
    "new_output = tree_cont.predict(new_input) \n",
    "new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70639854])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify the workflow above for regression\n",
    "# Example code below uses sklearn regression packages [used in week 6] rather than statsmodels [used in week 5]; either will work\n",
    "from sklearn.linear_model import LinearRegression # or LogisticRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "new_output = model.predict(new_input)\n",
    "new_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
